---
tplVersion: 2

config:
  agent:
    flush_interval: "2s"
    flush_jitter: "1s"
    metric_batch_size: 1000
    omit_hostname: true

  inputs:
  - kafka_consumer:
      brokers: {{ dunedaq.kafka.bootstrap_brokers | tojson }}
      topics: {{ ERS_telegraf.kafka_topics | tojson }}
      version: "{{ dunedaq.kafka.version }}"
      client_id: 'ers-telegraf'
      consumer_group: 'ers-telegraf'
      data_format: 'xpath_json'
      xpath:
        - metric_name: "string('ErrorReports')"
          # These are the fields in the ERS messages
          # see erskafka/src/KafkaStream.cpp
          fields:
            application_name: "/application_name"
            chain: "/chain"
            cwd: "/cwd"
            file_name: "/file_name"
            function_name: "/function_name"
            #group_hash: "string(/group_hash)" # technically hex? but we're not using it
            host_name: "/host_name"
            issue_name: "/issue_name"
            message: "/message"
            package_name: "/package_name"
            params: "/params"
            partition: "/partition"
            qualifiers: "/qualifiers"
            severity: "/severity"
            user_name: "/user_name"
          fields_int:
            line_number: "number(/line_number)"
            process_id: "number(/process_id)"
            thread_id: "number(/thread_id)"
            time: "number(/time)" # this column is kinda redundant
            usecs_since_epoch: "number(/usecs_since_epoch)" # this column is kinda redundant
            user_id: "number(/user_id)"
  - internal:
      collect_memstats: false
      tags:  
        metrics: "telegraf"

  outputs:
  - prometheus_client: # for prometheus
      listen: ":{{ ERS_telegraf.prometheus_port }}"
      tagpass:
        metrics:
          - "telegraf"
  - postgresql:
      connection: "{{ ERS_telegraf.postgresql_connection }}"
      tagdrop:
        metrics:
          - "telegraf"

  processors:
  - regex:
      namepass:
      - ErrorReports
      fields:
      - key: params
{% raw %}
        pattern: '(?P<value>\w+:\s*\w+)'
        replacement: '"${value}"'
      - key: qualifiers
        pattern: '(?P<value>\w+)'
        replacement: '"${value}"'
{% endraw %}
  - regex:
      namepass:
      - ErrorReports
      fields:
      - key: params
        pattern: '" "'
        replacement: '", "'
      - key: qualifiers
        pattern: '" "'
        replacement: '", "'

affinity:
  podAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions: # try to schedule near Kafka
          - key: "strimzi.io/cluster"
            operator: In
            values:
            - "{{ dunedaq.kafka.name }}"
        namespaceSelector:
          matchLabels:
            name: {{ dunedaq.kafka.namespace }}
        topologyKey: kubernetes.io/hostname
    - weight: 90
      podAffinityTerm:
        labelSelector:
          matchExpressions: # try to schedule near postgresql
          - key: "app.kubernetes.io/instance"
            operator: In
            values:
            - "ers-postgresql"
        namespaceSelector:
          matchLabels:
            name: {{ DUNE_ers.namespace }}
        topologyKey: kubernetes.io/hostname

resources:
  requests:
    cpu: 50m
    memory: 32Mi

nodeSelector:
  kubernetes.io/os: linux

metrics: # do this by hand so we can filter
  health:
    enabled: false
  internal:
    enabled: false
